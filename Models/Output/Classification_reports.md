# Random Forest

| Threshold >= 0.4| Precicion | Recall | FI-score | 
|-----------------|-----------|--------|----------|
| 0	| 0.765	| 0.706	| 0.734 |
| 1	| 0.283	| 0.348	| 0.312 |
| Accuracy | 0.725 | 
| Threshold >= 0.6 | | | |
| 0	| 0.755	| 0.937	| 0.837 |
| 1	| 0.322	| 0.089	| 0.14 |
| Accuracy | 0.725 |
| Threshold >= 0.7 | | | |
| 0 | 0.752 | 0.960 | 0.849 | 
| 1 | 0.347 | 0.038 | 0.061 |
| Accuracy | 0.74 |
| Threshold >= 0.8 | | | |
| 0 | 0.751 | 0.989 | 0.855 | 
| 1 | 0.324 | 0.015 | 0.029 |
| Accuracy | 0.725 |

As observed in the table above the RF achieved its maximum precision of 0.34, indicating that approximately one in three predicted positive interactions corresponded to experimentally supported regulatory relationships. However, this high precision was accompanied by a relatively low recall of 0.33, suggesting that a considerable proportion of true interactions were missed. When the classification threshold was relaxed to 0.4, the model exhibited a higher recall of 0.44, capturing a larger fraction of true positives, albeit at the cost of reduced precision (0.272). The corresponding overall accuracy at this threshold was 0.579, reflecting a modest balance between the two metrics.

# XGBoost

| Threshold >= 0.4| Precicion | Recall | FI-score | 
|-----------------|-----------|--------|----------|
| 0	| 0.765	| 0.706	| 0.167 |
| 1	| 0.256	| 0.939	| 0.402 |
| Accuracy | 0.304 |
| Threshold >= 0.5 | | | |
| 0	| 0.756	| 0.816	| 0.788 |
| 1	| 0.298	| 0.234	| 0.263 |
| Accuracy | 0.671 |
| Threshold >= 0.6 | | | |
| 0	| 0.755	| 0.937	| 0.837 |
| 1	| 0.322	| 0.089	| 0.140 |
| Accuracy | 0.725 |
| Threshold >= 0.7 | | | |
| 0 | 0.752 | 0.960 | 0.849 | 
| 1 | 0.347 | 0.038 | 0.061 |
| Accuracy | 0.740 |
| Threshold >= 0.8 | | | |
| 0 | 0.751 | 0.989 | 0.855 | 
| 1 | 0.324 | 0.015 | 0.029 |
| Accuracy | 0.725 |

The XGBoost model on the other hand, demonstrated superior overall performance, particularly in terms of precision at higher thresholds (Table 2). At a threshold of 0.8, XGBoost achieved a maximum precision of 0.61, more than 75% higher than that of the RF at its corresponding optimum. However, this high precision came with an extremely low recall of 0.009, indicating a highly conservative classification behavior where only a small fraction of positive examples were identified. When the threshold was reduced to 0.4, XGBoost achieved a substantially higher recall of 0.969, successfully recovering most true interactions, although precision decreased to 0.255 due to an increased number of false positives.

# Ensemble

| Threshold >= 0.4| Precicion | Recall | FI-score | 
|-----------------|-----------|--------|----------|
| 0	| 0.774	| 0.574	| 0.659 |
| 1	| 0.280	| 0.497	| 0.358 |
| Accuracy | 0.555 |
| Threshold >= 0.5 | | | |
| 0	| 0.767	| 0.787	| 0.777 |
| 1	| 0.307	| 0.284	| 0.295 |
| Accuracy | 0.661 |
| Threshold >= 0.6 | | | |
| 0	| 0.757	| 0.959	| 0.846 |
| 1	| 0.378	| 0.075	| 0.125 |
| Accuracy | 0.738 |
| Threshold >= 0.7 | | | |
| 0 | 0.753 | 0.990 | 0.855 | 
| 1 | 0.454 | 0.024 | 0.045 |
| Accuracy | 0.749 |
| Threshold >= 0.8 | | | |
| 0 | 0.751 | 0.998 | 0.857 | 
| 1 | 0.505 | 0.005 | 0.010 |
| Accuracy | 0.750 |

The ensemble model, generated by averaging the predicted probabilities from the RF and XGBoost classifiers, was evaluated across multiple classification thresholds ranging from 0.4 to 0.8 (Table 4). At a lower threshold of 0.4, the model achieved a moderate balance, with a precision of 0.774 and recall of 0.574 for the negative class (0), and a precision of 0.280 and recall of 0.497 for the positive class (1), resulting in an overall accuracy of 0.555. As the threshold increased to 0.5 and above, the model exhibited higher precision but lower recall, highlighting the classical precisionâ€“recall trade-off. Higher thresholds improved confidence in predicted edges but also increased the likelihood of missing true regulatory interactions, producing more false negatives, whereas lower thresholds risked including more false positives.


 # CONCLUSION
 The model predicts negative edges more confidently, but struggles to predict the positives. This may be due to sparse data and high negatives present than the positives. However, the XGBoost seems to perform better than RF and the Ensemble model, indicating that this model may predict a more biological meaningful GRN comparitively.
